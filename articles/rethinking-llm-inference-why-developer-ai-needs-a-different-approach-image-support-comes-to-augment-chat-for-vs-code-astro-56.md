---
title: 'Rethinking Llm Inference Why Developer Ai Needs A Different Approach Image Support Comes To Augment Chat For Vs Code Astro 56'
excerpt: 'Przegląd 4 artykułów z ui.dev'
publishedAt: '2025-10-26'
slug: 'rethinking-llm-inference-why-developer-ai-needs-a-different-approach-image-support-comes-to-augment-chat-for-vs-code-astro-56'
hashtags: '#generated #pl #ai #frontend #backend'
---

## Rethinking LLM inference: Why developer AI needs a different approach

No, słuchajcie, to jest naprawdę interesujące. Augment Code pokazuje, dlaczego obecne podejście do AI w kodowaniu jest kompletnie błędne. Wszyscy skupiają się na chatbotach, które mają krótkie prompty i długie odpowiedzi, ale kodowanie to zupełnie inna bajka.

Kontekst to wszystko w kodowaniu. Nie możesz zmieniać kodu patrząc tylko na jeden plik. Musisz wiedzieć o zależnościach, miejscach wywołań, README, plikach buildowych, bibliotekach zewnętrznych. Augment odkrył, że jakość predykcji dalej rośnie nawet po dziesięciu tysiącach tokenów kontekstu. To jest szalone!

Problem w tym, że istniejące rozwiązania jak vLLM czy TensorRT-LLM są zoptymalizowane pod czaty. Friendli.ai pokazało, że time to first token dla dziesięciu tysięcy tokenów w Llama3 70B to około tysiąca milisekund. Augment zrobił to w mniej niż trzysta milisekund. Trzy razy szybciej! To jest różnica między "czekam i się nudzę" a "to po prostu działa".

**Kluczowe wnioski:**
- Kontekst w kodowaniu to nie opcja, to konieczność
- Istniejące rozwiązania AI są zoptymalizowane pod złe przypadki użycia
- Augment osiągnął 3x lepszy TTFT dla długich kontekstów

**Link**: https://click.convertkit-mail4.com/v8u9lzv2ezbrhv4749daziv4xx8llh9/08hwhgu2o3dwp3bl/aHR0cHM6Ly9mbmYuZGV2LzRjZ2dDZ0o=

Kluczowe wnioski:
- - Kontekst w kodowaniu to nie opcja, to konieczność
- Istniejące rozwiązania AI są zoptymalizowane pod złe przypadki użycia
- Augment osiągnął 3x lepszy TTFT dla długich kontekstów

Link: 

## Image support comes to Augment Chat for VS Code

Okej, to jest naprawdę spoko feature. Augment dodał wsparcie dla obrazów w chacie VS Code. I nie, to nie jest kolejne "przyklej plik i miej nadzieję". Obrazy są wbudowane bezpośrednio w konwersację.

Pomyślcie o tym - ile razy próbowaliście opisać słowami, jak ma wyglądać UI? Albo tłumaczyć, co jest nie tak z layoutem? To jest frustrujące jak diabli. Teraz możecie po prostu wrzucić screenshot lub mockup, a AI widzi dokładnie to, co wy.

Najlepsze w tym jest to, że AI nie tylko widzi obraz, ale rozumie go w kontekście waszego kodu. Pokażecie mockup, a ono zasugeruje implementację używając waszych istniejących komponentów. To jest właśnie ta różnica między "AI które zna internet" a "AI które zna wasz projekt".

**Kluczowe wnioski:**
- Obrazy wbudowane bezpośrednio w konwersację, nie jako załączniki
- AI rozumie obrazy w kontekście konkretnego projektu
- Przyspiesza debugowanie wizualnych problemów i implementację UI

**Link**: https://click.convertkit-mail4.com/v8u9lzv2ezbrhv4749daziv4xx8llh9/vqh3hmuoxzp3qqhg/aHR0cHM6Ly9mbmYuZGV2LzRqajFIRVk=

Kluczowe wnioski:
- - Obrazy wbudowane bezpośrednio w konwersację, nie jako załączniki
- AI rozumie obrazy w kontekście konkretnego projektu
- Przyspiesza debugowanie wizualnych problemów i implementację UI

Link: 

## Astro 5.6

Astro wypuściło 5.6 i jest kilka rzeczy, które są naprawdę warte uwagi. Po pierwsze - globalne astro:env na Cloudflare. Do tej pory zmienne środowiskowe na Cloudflare były dostępne tylko w ramach requestu. To znaczy, że jeśli chcieliście stworzyć współdzielony klient API poza requestem, to mieliście problem. Teraz to działa globalnie, tak jak w innych adapterach.

Druga rzecz to eksperymentalne sesje na Cloudflare. Astro automatycznie konfiguruje Cloudflare KV storage dla sesji. To znaczy, że wasze dane sesji są niezawodnie przechowywane i dostępne w całej globalnej sieci Cloudflare z minimalną konfiguracją.

Dodali też nową opcję prefetch eagerness, która daje więcej kontroli nad tym, kiedy i jak zasoby są pobierane z wyprzedzeniem. Plus kilka pomniejszych ulepszeń i breaking changes w eksperymentalnym SVG API.

**Kluczowe wnioski:**
- Globalne zmienne środowiskowe na Cloudflare - w końcu!
- Automatyczna konfiguracja KV storage dla sesji
- Lepsza kontrola nad prefetchingiem

**Link**: https://click.convertkit-mail4.com/v8u9lzv2ezbrhv4749daziv4xx8llh9/e0hph0u7p80wzpt8/aHR0cHM6Ly9hc3Ryby5idWlsZC9ibG9nL2FzdHJvLTU2MC8=

Kluczowe wnioski:
- - Globalne zmienne środowiskowe na Cloudflare - w końcu!
- Automatyczna konfiguracja KV storage dla sesji
- Lepsza kontrola nad prefetchingiem

Link: 

## Digital Experience Monitoring Solution Brief | Datadog

Datadog promuje swój Digital Experience Monitoring suite. To narzędzie do monitorowania frontend'u, które ma pomóc zespołom w debugowaniu problemów, lepszej współpracy i dostarczaniu dobrego user experience.

Oferują synthetic testy na różnych środowiskach, urządzeniach i przeglądarkach, eliminację silosów danych dla lepszej współpracy UX, priorytetyzację problemów na podstawie ważności i częstotliwości, oraz pełną widoczność stacku dla redukcji czasu wykrywania i naprawiania problemów.

Brzmi jak typowy enterprise monitoring tool. Może być przydatny dla większych zespołów, które mają problemy z koordynacją między frontend'em a backend'em.

**Kluczowe wnioski:**
- Kompleksowe monitorowanie doświadczenia użytkownika
- Synthetic testy na wielu platformach
- Integracja z pełnym stackiem dla lepszego debugowania

**Link**: https://click.convertkit-mail4.com/v8u9lzv2ezbrhv4749daziv4xx8llh9/dphehmue4l0wxzbm/aHR0cHM6Ly93d3cuZGF0YWRvZ2hxLmNvbS9yZXNvdXJjZXMvZGlnaXRhbC1leHBlcmllbmNlLW1vbml0b3Jpbmctc29sdXRpb24tYnJpZWYvP3V0bV9jYW1wYWlnbj1kZy1hcG0td3ctZGVtLWJyaWVmLWJ5dGVzJnV0bV9tZWRpdW09bmV3c2xldHRlciZ1dG1fc291cmNlPWJ5dGVzZGV2

Kluczowe wnioski:
- - Kompleksowe monitorowanie doświadczenia użytkownika
- Synthetic testy na wielu platformach
- Integracja z pełnym stackiem dla lepszego debugowania

Link: