---
title: "China's AI Milestones in 2025: DeepSeek, Qwen, and the Open-Source Revolution"
excerpt: "How Chinese AI labs achieved open-source dominance, launched reasoning models, and built a semiconductor ecosystem despite chip restrictions"
publishedAt: "2025-12-27"
slug: "china-ai-milestones-2025-deepseek-qwen-open-source"
hashtags: "#substack #ai #llm #deepseek #open-source #china #architecture #generated #en"
---

## Milestones of China in AI of 2025

**TLDR:** China's AI ecosystem achieved remarkable progress in 2025, with open-source models capturing 17.1% of global downloads to surpass the US, 570 million generative AI users, and reasoning models from DeepSeek and Qwen closing the gap with frontier labs—all accomplished with limited access to advanced chips and a fraction of US capital expenditure.

**Summary:**

The numbers tell a story that challenges the conventional narrative about AI leadership. Chinese open-source models now account for 17.1% of global downloads, ranking first globally and representing a dramatic shift from 1.2% in late 2024 to nearly 30% of global AI usage. China's generative AI user base hit 570 million by February 2025, with a staggering 106.6% growth rate in the first six months of the year. These aren't marginal gains—this is ecosystem velocity.

What makes this particularly notable is the constraint under which it was achieved. China managed this with severely limited access to leading AI chips and with capex that's a fraction of what US hyperscalers are deploying. While Alibaba and ByteDance are starting to enter the capital expenditure territory of global leaders, the efficiency story is remarkable. DeepSeek's approach demonstrated that you can achieve frontier-class reasoning with significantly less compute—a lesson that has implications for the entire industry's assumptions about scaling.

The "Six Little Dragons" of Chinese AI grew up substantially in 2025. Moonshot AI's Kimi K2, Zhipu AI's GLM-4 (now open-sourced as GLM-4.7), and MiniMax models have closed the gap with US frontiers in complex reasoning. The pattern here is consistent: open-weight releases with steady streams of free, high-performance updates that attract developers and builders. This is a deliberate strategy—while leading US labs like OpenAI and Google focus on proprietary, closed-source frontier models, Chinese firms have embraced accessibility and customizability.

The semiconductor story deserves attention from anyone thinking about geopolitical technology dynamics. Huawei's Ascend 950/960 series and Kirin chips now power over 50% of domestic data centers, reducing Nvidia reliance. Huawei is estimated to produce roughly 800,000 to 1,000,000 AI chip dies in 2025, with plans to double output for the Ascend 910 series in 2026. Even more significant: China is reportedly testing a prototype EUV lithography machine—part of a six-year "Manhattan Project" initiative to bypass Western export controls. While chip output targets are 2028-2030, this is significantly faster than anticipated.

For architects and teams, the strategic implications are substantial. Qwen (Alibaba) models have essentially taken over the position Meta's Llama held as the default foundational open-source model for startups. If you're building on open-source foundations, understanding the capabilities and licensing of Chinese models becomes essential. The agentic AI space is also maturing rapidly—Manus achieved 57.7% accuracy on high-level GAIA benchmarks, and 2025 is cited as the year AI agents moved from chat interfaces to autonomous task execution.

The physical AI and humanoid robotics space is also accelerating, with multiple Chinese companies approaching IPOs. Moore Threads saw a 425% stock jump on its first trading day, MetaX gained 693% on listing. The convergence of AI chips, robotics, and abundant energy infrastructure positions China for significant scaling capability—potentially at costs well below US equivalents.

**Key takeaways:**
- Chinese open-source AI models now lead globally at 17.1% of downloads, up from 1.2% in late 2024
- DeepSeek-R2 and similar reasoning models achieved frontier performance with a fraction of US compute budgets
- Huawei Ascend chips now power 50%+ of Chinese data centers, with production doubling planned for 2026
- Qwen has replaced Llama as the default open-source foundation model for many startups globally
- China's EUV lithography "Manhattan Project" is ahead of schedule, targeting chip output by 2028-2030

**Tradeoffs:**
- Open-weight model strategy maximizes adoption but sacrifices potential monetization and control over capabilities
- Domestic chip independence reduces supply chain risk but current generation remains 6-12 years behind TSMC
- Lower capex requirements enable broader participation but may limit peak capability compared to US hyperscaler investments

**Link:** [Milestones of China in AI of 2025](https://www.ai-supremacy.com/p/milestones-of-china-in-ai-of-2025-deepseek-qwen)

---

*This article summary was generated based on newsletter content. The views and opinions expressed in the original article belong to the respective authors.*
